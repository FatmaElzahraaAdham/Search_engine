{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'], ['antony', 'brutus', 'caeser', 'calpurnia'], ['mercy', 'worser'], ['brutus', 'caeser', 'mercy', 'worser'], ['caeser', 'mercy', 'worser'], ['antony', 'caeser', 'mercy'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'], ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']]\n",
      "[['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser'], ['antoni', 'brutu', 'caeser', 'calpurnia'], ['merci', 'worser'], ['brutu', 'caeser', 'merci', 'worser'], ['caeser', 'merci', 'worser'], ['antoni', 'caeser', 'merci'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where'], ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']]\n",
      "Document 1: ['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser']\n",
      "Document 2: ['antoni', 'brutu', 'caeser', 'calpurnia']\n",
      "Document 3: ['merci', 'worser']\n",
      "Document 4: ['brutu', 'caeser', 'merci', 'worser']\n",
      "Document 5: ['caeser', 'merci', 'worser']\n",
      "Document 6: ['antoni', 'caeser', 'merci']\n",
      "Document 7: ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 8: ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 9: ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 10: ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "OrderedDict({'angel': [3, OrderedDict({6: [0], 7: [0], 8: [0]})], 'antoni': [3, OrderedDict({0: [0], 1: [0], 5: [0]})], 'brutu': [3, OrderedDict({0: [1], 1: [1], 3: [0]})], 'caeser': [5, OrderedDict({0: [2], 1: [2], 3: [1], 4: [0], 5: [1]})], 'calpurnia': [1, OrderedDict({1: [3]})], 'cleopatra': [1, OrderedDict({0: [3]})], 'fear': [3, OrderedDict({6: [2], 7: [2], 9: [1]})], 'fool': [4, OrderedDict({6: [1], 7: [1], 8: [1], 9: [0]})], 'in': [4, OrderedDict({6: [3], 7: [3], 8: [2], 9: [2]})], 'merci': [5, OrderedDict({0: [4], 2: [0], 3: [2], 4: [1], 5: [2]})], 'rush': [4, OrderedDict({6: [4], 7: [4], 8: [3], 9: [3]})], 'to': [4, OrderedDict({6: [5], 7: [5], 8: [4], 9: [4]})], 'tread': [4, OrderedDict({6: [6], 7: [6], 8: [5], 9: [5]})], 'where': [4, OrderedDict({6: [7], 7: [7], 8: [6], 9: [6]})], 'worser': [4, OrderedDict({0: [5], 2: [1], 3: [3], 4: [2]})]})\n",
      "[[], [], [], [], [], [], [], [], [], []]\n",
      "[[], [], [], [], [], [1, 2], [1, 2], [1], [0, 1], []]\n",
      "6\n",
      "7\n",
      "9\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni        1     1     0     0     0     1     0     0     0      0\n",
      "brutu         1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "merci         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angel         0     0     0     0     0     0     1     1     1      0\n",
      "fool          0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutu       1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "merci       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angel       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fool        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "          freq       idf\n",
      "antoni     3.0  0.522879\n",
      "brutu      3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "merci      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angel      3.0  0.522879\n",
      "fool       4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antoni          0.0       0.0       0.0  \n",
      "brutu           0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "merci           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angel      0.522879  0.522879       0.0  \n",
      "fool        0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "   doc1_len  doc2_len  doc3_len  doc4_len  doc5_len  doc6_len  doc7_len  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747   0.67427  1.223496   \n",
      "\n",
      "   doc8_len  doc9_len  doc10_len  \n",
      "0  1.223496  1.106137   1.106137  \n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antoni     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutu      0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "merci      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antoni     0.000000  0.000000  0.000000  0.000000  \n",
      "brutu      0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "merci      0.000000  0.000000  0.000000  0.000000  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "angel      0.427365  0.427365  0.472707  0.000000  \n",
      "fool       0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphase1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m documents\u001b[38;5;241m=\u001b[39m stemmed_doc\n\u001b[0;32m      8\u001b[0m all_words\u001b[38;5;241m=\u001b[39m[]\n",
      "File \u001b[1;32mc:\\Users\\H P\\Downloads\\IR_project_f2\\main.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m tf_idf_norm_res, tfd_res \u001b[38;5;241m=\u001b[39m tf_IDF_norm(stemmed_doc)\n\u001b[0;32m     16\u001b[0m q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease enter the query : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mphrse_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_idf_norm_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfd_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# len = phrse_query_length(query_ph,q)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\H P\\Downloads\\IR_project_f2\\phrase_query.py:130\u001b[0m, in \u001b[0;36mphrse_query\u001b[1;34m(q, normalized_term_freq_idf, tfd)\u001b[0m\n\u001b[0;32m    128\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(query)):\n\u001b[1;32m--> 130\u001b[0m     query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m product2\u001b[38;5;241m=\u001b[39mproduct\u001b[38;5;241m.\u001b[39mmultiply(query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# product2\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from phase1 import *\n",
    "from main import *\n",
    "\n",
    "documents= stemmed_doc\n",
    "all_words=[]\n",
    "\n",
    "for doc in documents:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    "\n",
    "# print(dict.fromkeys(all_words,0))\n",
    "\n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word] +=1\n",
    "    return words_found\n",
    "\n",
    "term_freq= pd.DataFrame(get_term_freq(documents[0]).values(),index=get_term_freq(documents[0]).keys())\n",
    "\n",
    "\n",
    "for i in range(1,len(documents)):\n",
    "    term_freq[i]= get_term_freq(documents[i]).values()\n",
    "\n",
    "# print(term_freq)\n",
    "\n",
    "term_freq.columns=['doc'+ str(i) for i in range(1,11)]\n",
    "print(term_freq)\n",
    "\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "        return math.log(x)+1\n",
    "    return 0\n",
    "\n",
    "for i in range (1,len(documents)+1):\n",
    "    term_freq['doc'+str(i)]=term_freq['doc'+str(i)].apply(get_weighted_term_freq)\n",
    "\n",
    "print(term_freq)\n",
    "# idf is log(doc num/ term freq in doc)\n",
    "tfd=pd.DataFrame(columns=['freq','idf'])\n",
    "\n",
    "for i in range(len(term_freq)):\n",
    "\n",
    "    frequency=term_freq.iloc[i].values.sum()\n",
    "\n",
    "    tfd.loc[i ,'freq']= frequency\n",
    "\n",
    "    tfd.loc[i ,'idf']=math.log10(10 / float((frequency)) )\n",
    "\n",
    "tfd.index= term_freq.index\n",
    "print(tfd)    \n",
    "\n",
    "\n",
    "##### TF IDF #####\n",
    "\n",
    "term_freq_inverse_doc_freq= term_freq.multiply(tfd['idf'], axis=0)\n",
    "\n",
    "print(term_freq_inverse_doc_freq)\n",
    "\n",
    "\n",
    "####### doc length\n",
    "\n",
    "document_length=pd.DataFrame()\n",
    "\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inverse_doc_freq[col].apply(lambda x : x**2).sum())\n",
    "\n",
    "for column in term_freq_inverse_doc_freq.columns:\n",
    "    document_length.loc[0 , column+'_len']= get_docs_length(column)\n",
    "\n",
    "print(document_length)\n",
    "\n",
    "\n",
    "#### normalized TF IDF ######\n",
    "\n",
    "\n",
    "normalized_term_freq_idf= pd.DataFrame()\n",
    "\n",
    "def get_normalized(col , x):\n",
    "    try:\n",
    "        return x / document_length[col+'_len'].values[0]\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "for column in term_freq_inverse_doc_freq.columns:\n",
    "    normalized_term_freq_idf[column]= term_freq_inverse_doc_freq[column].apply(lambda x : get_normalized(column , x))\n",
    "\n",
    "normalized_term_freq_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_term_freq_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m q\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mantony AND brutus\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# def phrse_query(q):\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# porter = PorterStemmer()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# query_tokens = word_tokenize(q)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# stemmed_query = [porter.stem(token) for token in query_tokens]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# q= ' '.join(stemmed_query)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mquery_boolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36mquery_boolean\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m     19\u001b[0m     query_terms \u001b[38;5;241m=\u001b[39m [term\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m q\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize an empty dataframe\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m query_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39m\u001b[43mnormalized_term_freq_idf\u001b[49m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query_terms:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Stem each term\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     term_tokens \u001b[38;5;241m=\u001b[39m word_tokenize(term)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_term_freq_idf' is not defined"
     ]
    }
   ],
   "source": [
    "q= 'antony AND brutus'\n",
    "# def phrse_query(q):\n",
    "# porter = PorterStemmer()\n",
    "# query_tokens = word_tokenize(q)\n",
    "# stemmed_query = [porter.stem(token) for token in query_tokens]\n",
    "# q= ' '.join(stemmed_query)\n",
    "query_boolean(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_term_freq_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m query \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39m\u001b[43mnormalized_term_freq_idf\u001b[49m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      2\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m q\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(normalized_term_freq_idf\u001b[38;5;241m.\u001b[39mindex)]\n\u001b[0;32m      3\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_tf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mquery[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : get_weighted_term_freq(x))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_term_freq_idf' is not defined"
     ]
    }
   ],
   "source": [
    "query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "query['tf']=[1 if x in q.split() else 0 for x in list(normalized_term_freq_idf.index)]\n",
    "query['w_tf']=query['tf'].apply(lambda x : get_weighted_term_freq(x))\n",
    "product = normalized_term_freq_idf.multiply(query['w_tf'], axis=0)\n",
    "query['idf']=tfd['idf'] * query['w_tf']\n",
    "query['tf_idf']=query['w_tf'] * query['idf']\n",
    "query['norm']=0\n",
    "for i in range(len(query['norm'])):\n",
    "   query['norm'].iloc[i]= float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n",
    "\n",
    "product2 = product.multiply(query['norm'],axis=0)\n",
    "scores = {}\n",
    "for col in product2.columns:\n",
    "  if 0 in product2[col].loc[q.split()].values:\n",
    "    pass\n",
    "  else:\n",
    "    scores[col] = product2[col].sum()\n",
    "\n",
    "print(query.loc[q.split()])\n",
    "print(\"----------------------------prod-ðŸ˜----------------------------------\")\n",
    "print(product2[list(scores.keys())].loc[q.split()])\n",
    "print(\"----------------------------prod_res.sum()ðŸ˜----------------------------------\")\n",
    "print(prod_res.sum())\n",
    "#sum\n",
    "scores = {}\n",
    "for col in product2.columns:\n",
    "  if 0 in product2[col].loc[q.split()].values:\n",
    "    pass\n",
    "  else:\n",
    "    scores[col] = product2[col].sum()\n",
    "print(\"----------------------------sim_score-ðŸ˜----------------------------------\")\n",
    "print(\"\\n\")\n",
    "print(scores ,\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#query length\n",
    "print(\"----------------------------DOC_LEN-ðŸ˜----------------------------------\")\n",
    "\n",
    "print(math.sqrt(sum([x**2 for x in query['idf'].loc[q.split()]])))\n",
    "print(\"\\n\")\n",
    "\n",
    "#returned\n",
    "final_score = sorted(scores.items(), key=lambda x: x[1] , reverse=True)\n",
    "print(\"----------------------------returned docs-ðŸ˜----------------------------------\")\n",
    "for doc in final_score:\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print(doc[0],end='')\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: antony OR brutus\n",
      "Preprocessed Query: ['antoni', 'or', 'brutu']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Query:\u001b[39m\u001b[38;5;124m'\u001b[39m, user_query)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreprocessed Query:\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessed_query)\n\u001b[1;32m---> 81\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mput_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositional_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched Documents:\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m, in \u001b[0;36mput_query\u001b[1;34m(query, positional_index)\u001b[0m\n\u001b[0;32m     36\u001b[0m     positions \u001b[38;5;241m=\u001b[39m perform_and_operation(preprocessed_query1, preprocessed_query2, positional_index)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m boolean_operator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOR\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     positions \u001b[38;5;241m=\u001b[39m \u001b[43mperform_or_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_query1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessed_query2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositional_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m boolean_operator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOT\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     40\u001b[0m     positions \u001b[38;5;241m=\u001b[39m perform_not_operation(preprocessed_query1, preprocessed_query2, positional_index)\n",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m, in \u001b[0;36mperform_or_operation\u001b[1;34m(query1, query2, positional_index)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_or_operation\u001b[39m(query1, query2, positional_index):\n\u001b[1;32m---> 67\u001b[0m     positions1 \u001b[38;5;241m=\u001b[39m \u001b[43mfind_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositional_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     positions2 \u001b[38;5;241m=\u001b[39m find_positions(query2, positional_index)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(positions1) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(positions2)\n",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m, in \u001b[0;36mfind_positions\u001b[1;34m(preprocessed_query, positional_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m lis \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]  \n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m preprocessed_query:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpositional_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m():\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m positional_index[term][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     49\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m lis[key] \u001b[38;5;241m!=\u001b[39m []:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "#  AND , OR , NOT Ø§Ø´ØªØºÙ„ \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Instantiate Porter Stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_query(query):\n",
    "    # Tokenize the query and stem each term\n",
    "    token_docs = word_tokenize(query)\n",
    "    prepared_doc = [porter.stem(term) for term in token_docs]\n",
    "    return prepared_doc\n",
    "\n",
    "def put_query(query, positional_index):\n",
    "    boolean_operators = ['AND', 'OR', 'NOT']\n",
    "    boolean_operator = None\n",
    "\n",
    "    # Check if any boolean operator is present in the query\n",
    "    for operator in boolean_operators:\n",
    "        if operator in query:\n",
    "            boolean_operator = operator\n",
    "            break\n",
    "\n",
    "    # If no boolean operator is present, treat the entire query as a phrase\n",
    "    if boolean_operator is None:\n",
    "        preprocessed_query = preprocess_query(query)\n",
    "        positions = find_positions(preprocessed_query, positional_index)\n",
    "    else:\n",
    "        # Split the query based on the boolean operator\n",
    "        query_parts = query.split(boolean_operator)\n",
    "        preprocessed_query1 = preprocess_query(query_parts[0].strip())\n",
    "        preprocessed_query2 = preprocess_query(query_parts[1].strip())\n",
    "\n",
    "        if boolean_operator == 'AND':\n",
    "            positions = perform_and_operation(preprocessed_query1, preprocessed_query2, positional_index)\n",
    "        elif boolean_operator == 'OR':\n",
    "            positions = perform_or_operation(preprocessed_query1, preprocessed_query2, positional_index)\n",
    "        elif boolean_operator == 'NOT':\n",
    "            positions = perform_not_operation(preprocessed_query1, preprocessed_query2, positional_index)\n",
    "\n",
    "    return positions\n",
    "\n",
    "def find_positions(preprocessed_query, positional_index):\n",
    "    lis = [[] for i in range(10)]  \n",
    "    for term in preprocessed_query:\n",
    "        if term in positional_index.keys():\n",
    "            for key in positional_index[term][1].keys():\n",
    "                if lis[key] != []:\n",
    "                    if lis[key][-1] == positional_index[term][1][key][0] - 1:\n",
    "                        lis[key].append(positional_index[term][1][key][0])\n",
    "                else:\n",
    "                    lis[key].append(positional_index[term][1][key][0])\n",
    "\n",
    "    positions = []\n",
    "    for pos, lst in enumerate(lis, start=1):\n",
    "        if len(lst) == len(preprocessed_query):\n",
    "            positions.append('document ' + str(pos))\n",
    "    return positions\n",
    "\n",
    "def perform_and_operation(query1, query2, positional_index):\n",
    "    positions1 = find_positions(query1, positional_index)\n",
    "    positions2 = find_positions(query2, positional_index)\n",
    "    return set(positions1) & set(positions2)\n",
    "\n",
    "def perform_or_operation(query1, query2, positional_index):\n",
    "    positions1 = find_positions(query1, positional_index)\n",
    "    positions2 = find_positions(query2, positional_index)\n",
    "    return set(positions1) | set(positions2)\n",
    "\n",
    "def perform_not_operation(query1, query2, positional_index):\n",
    "    positions1 = find_positions(query1, positional_index)\n",
    "    positions2 = find_positions(query2, positional_index)\n",
    "    return set(positions1) - set(positions2)\n",
    "\n",
    "\n",
    "user_query = input(\"Enter your boolean query: \")\n",
    "preprocessed_query = preprocess_query(user_query)\n",
    "print('Original Query:', user_query)\n",
    "print('Preprocessed Query:', preprocessed_query)\n",
    "result = put_query(user_query, positional_index)\n",
    "print('Matched Documents:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Assume normalized_term_freq_idf, tfd, and other required functions are defined\n",
    "\n",
    "def query_boolean(q):\n",
    "    porter = PorterStemmer()\n",
    "    query_tokens = word_tokenize(q)\n",
    "    stemmed_query = [porter.stem(token) for token in query_tokens]\n",
    "\n",
    "    # Check for boolean operators\n",
    "    if ' AND ' in q:\n",
    "        operator = 'AND'\n",
    "        query_terms = [term.strip() for term in q.split('AND')]\n",
    "    elif ' OR ' in q:\n",
    "        operator = 'OR'\n",
    "        query_terms = [term.strip() for term in q.split('OR')]\n",
    "    else:\n",
    "        operator = 'AND'  # Default to OR if no explicit operator is provided\n",
    "        query_terms = [term.strip() for term in q.split()]\n",
    "\n",
    "    # Initialize an empty dataframe\n",
    "    query_result = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "\n",
    "    for term in query_terms:\n",
    "        # Stem each term\n",
    "        term_tokens = word_tokenize(term)\n",
    "        stemmed_term = [porter.stem(token) for token in term_tokens]\n",
    "\n",
    "        # Create a query vector for the current term\n",
    "        query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "        query['tf'] = [1 if x in stemmed_term else 0 for x in normalized_term_freq_idf.index]\n",
    "        query['w_tf'] = query['tf'].apply(lambda x: get_weighted_term_freq(x))\n",
    "        query['idf'] = tfd['idf'] * query['w_tf']\n",
    "        query['tf_idf'] = query['idf'] * query['w_tf']\n",
    "        query['norm'] = normalize(query[['idf']], norm='l2', axis=0)\n",
    "\n",
    "        # Perform AND or OR operation\n",
    "        if operator == 'AND':\n",
    "            query_result = pd.concat([query_result, query], axis=1, join='inner')  # Use inner join for AND\n",
    "        elif operator == 'OR':\n",
    "            query_result = pd.concat([query_result, query], axis=1, join='outer')\n",
    "\n",
    "    # Return the final result after AND or OR operation\n",
    "    return query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H P\\AppData\\Local\\Temp\\ipykernel_4120\\1056851837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query['norm'].iloc[i]= float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n",
      "C:\\Users\\H P\\AppData\\Local\\Temp\\ipykernel_4120\\1056851837.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.7071067811865475' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  query['norm'].iloc[i]= float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>w_tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tf  w_tf       idf    tf_idf      norm\n",
       "antoni      1   1.0  0.522879  0.522879  0.707107\n",
       "brutu       1   1.0  0.522879  0.522879  0.707107\n",
       "caeser      0   0.0       0.0       0.0  0.000000\n",
       "cleopatra   0   0.0       0.0       0.0  0.000000\n",
       "merci       0   0.0       0.0       0.0  0.000000\n",
       "worser      0   0.0       0.0       0.0  0.000000\n",
       "calpurnia   0   0.0       0.0       0.0  0.000000\n",
       "angel       0   0.0       0.0       0.0  0.000000\n",
       "fool        0   0.0       0.0       0.0  0.000000\n",
       "fear        0   0.0       0.0       0.0  0.000000\n",
       "in          0   0.0       0.0       0.0  0.000000\n",
       "rush        0   0.0       0.0       0.0  0.000000\n",
       "to          0   0.0       0.0       0.0  0.000000\n",
       "tread       0   0.0       0.0       0.0  0.000000\n",
       "where       0   0.0       0.0       0.0  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def query_norm_idf(q):\n",
    "    # phrse_query('fools fear')\n",
    "porter = PorterStemmer()\n",
    "query_tokens = word_tokenize(q)\n",
    "stemmed_query = [porter.stem(token) for token in query_tokens]\n",
    "q= ' '.join(stemmed_query)\n",
    "query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "query['tf']=[1 if x in q.split() else 0 for x in normalized_term_freq_idf.index]\n",
    "query['w_tf']= query['tf'].apply(lambda x: get_weighted_term_freq(x))\n",
    "product = normalized_term_freq_idf.multiply(query['w_tf'], axis= 0)\n",
    "            # product\n",
    "query['idf'] = tfd['idf'] * query['w_tf']\n",
    "query['tf_idf'] = query['idf'] * query['w_tf']\n",
    "query['norm']=0\n",
    "for i in range(len(query)):\n",
    "    query['norm'].iloc[i]= float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n",
    "product2=product.multiply(query['norm'], axis=0)\n",
    "    # product2\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# query_norm_idf('fools fear')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mquery_norm_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mantony brutus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mquery_norm_idf\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m     10\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(query)):\n\u001b[1;32m---> 12\u001b[0m     query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m product2\u001b[38;5;241m=\u001b[39mproduct\u001b[38;5;241m.\u001b[39mmultiply(query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# product2\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# # query_norm_idf('fools fear')\n",
    "# print(query_norm_idf('antony brutus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['and'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m query_length\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m([x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m]))\n\u001b[0;32m      2\u001b[0m query_length\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\H P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['and'] not in index\""
     ]
    }
   ],
   "source": [
    "query_length=math.sqrt(sum([x**2 for x in query['idf'].loc[q.split()]]))\n",
    "query_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'builtin_function_or_method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     stemmed_term \u001b[38;5;241m=\u001b[39m [porter\u001b[38;5;241m.\u001b[39mstem(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m term_tokens]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Check if the term is present in the query vector\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstemmed_term\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m:\n\u001b[0;32m     10\u001b[0m         query_length \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[stemmed_term[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Take the square root of the sum of squared IDF values\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'builtin_function_or_method' is not iterable"
     ]
    }
   ],
   "source": [
    "query_length = 0\n",
    "\n",
    "# Iterate through the query terms\n",
    "for term in q.split():\n",
    "    term_tokens = word_tokenize(term)\n",
    "    stemmed_term = [porter.stem(token) for token in term_tokens]\n",
    "\n",
    "    # Check if the term is present in the query vector\n",
    "    if stemmed_term[0] in query.index:\n",
    "        query_length += query['idf'].loc[stemmed_term[0]] ** 2\n",
    "\n",
    "# Take the square root of the sum of squared IDF values\n",
    "query_length = math.sqrt(query_length)\n",
    "query_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for col in product2.columns:\n",
    "    if 0 in product2[col].loc[q.split()].values:\n",
    "        pass\n",
    "    else:\n",
    "        scores[col]=product2[col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "# Iterate through the columns of the product2 dataframe\n",
    "for col in product2.columns:\n",
    "    # Extract the relevant IDF values from the query vector\n",
    "    query_idf_values = query['idf'].loc[product2.index]\n",
    "\n",
    "    # Check if any of the relevant IDF values is zero\n",
    "    if 0 in query_idf_values.values:\n",
    "        # Skip if any term in the query has IDF of 0\n",
    "        pass\n",
    "    else:\n",
    "        # Calculate the score by summing the product of normalized TF-IDF values and query IDF values\n",
    "        scores[col] = (product2[col] * query_idf_values).sum()\n",
    "\n",
    "# Print or use the scores as needed\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 0.2815141484620463,\n",
       " 'doc2': 0.302159654545043,\n",
       " 'doc3': 0.0,\n",
       " 'doc4': 0.24692096410061823,\n",
       " 'doc5': 0.0,\n",
       " 'doc6': 0.2867167166390384,\n",
       " 'doc7': 0.0,\n",
       " 'doc8': 0.0,\n",
       " 'doc9': 0.0,\n",
       " 'doc10': 0.0}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores = {}\n",
    "\n",
    "# Iterate through the columns of the product2 dataframe\n",
    "for col in product2.columns:\n",
    "    # Extract the relevant IDF values from the query vector\n",
    "    query_idf_values = query['idf'].loc[product2.index]\n",
    "\n",
    "    # Calculate the score by summing the product of normalized TF-IDF values and query IDF values\n",
    "    scores[col] = (product2[col] * query_idf_values).sum()\n",
    "\n",
    "# Filter out documents that don't contain any term from the query\n",
    "filtered_scores = {key: score for key, score in scores.items() if any(query['tf'].loc[product2.index].astype(bool))}\n",
    "filtered_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 0.2815141484620463,\n",
       " 'doc2': 0.302159654545043,\n",
       " 'doc3': 0.0,\n",
       " 'doc4': 0.24692096410061823,\n",
       " 'doc5': 0.0,\n",
       " 'doc6': 0.2867167166390384,\n",
       " 'doc7': 0.0,\n",
       " 'doc8': 0.0,\n",
       " 'doc9': 0.0,\n",
       " 'doc10': 0.0}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_res= product2[scores.keys()].loc[q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_res = product2[filtered_scores.keys()].loc[query.index.intersection(q.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "      <th>doc7</th>\n",
       "      <th>doc8</th>\n",
       "      <th>doc9</th>\n",
       "      <th>doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1      doc2  doc3      doc4  doc5      doc6  doc7  doc8  doc9  \\\n",
       "antoni  0.269196  0.288939   0.0  0.000000   0.0  0.548343   0.0   0.0   0.0   \n",
       "brutu   0.269196  0.288939   0.0  0.472234   0.0  0.000000   0.0   0.0   0.0   \n",
       "\n",
       "        doc10  \n",
       "antoni    0.0  \n",
       "brutu     0.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc1     0.538393\n",
       "doc2     0.577877\n",
       "doc3     0.000000\n",
       "doc4     0.472234\n",
       "doc5     0.000000\n",
       "doc6     0.548343\n",
       "doc7     0.000000\n",
       "doc8     0.000000\n",
       "doc9     0.000000\n",
       "doc10    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_sum=prod_res.sum()\n",
    "prod_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc2', 0.5778771030041435),\n",
       " ('doc6', 0.5483426496621455),\n",
       " ('doc1', 0.5383927937463102),\n",
       " ('doc4', 0.47223369916907476),\n",
       " ('doc3', 0.0),\n",
       " ('doc5', 0.0),\n",
       " ('doc7', 0.0),\n",
       " ('doc8', 0.0),\n",
       " ('doc9', 0.0),\n",
       " ('doc10', 0.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score=sorted(prod_sum.items(), key= lambda x :x[1], reverse= True)\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2 doc6 doc1 doc4 doc3 doc5 doc7 doc8 doc9 doc10 "
     ]
    }
   ],
   "source": [
    "for doc in final_score:\n",
    "    print(doc[0], end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
