{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser'], ['antoni', 'brutu', 'caeser', 'calpurnia'], ['merci', 'worser'], ['brutu', 'caeser', 'merci', 'worser'], ['caeser', 'merci', 'worser'], ['antoni', 'caeser', 'merci'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where'], ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']]\n",
      "Document 1: ['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser']\n",
      "Document 2: ['antoni', 'brutu', 'caeser', 'calpurnia']\n",
      "Document 3: ['merci', 'worser']\n",
      "Document 4: ['brutu', 'caeser', 'merci', 'worser']\n",
      "Document 5: ['caeser', 'merci', 'worser']\n",
      "Document 6: ['antoni', 'caeser', 'merci']\n",
      "Document 7: ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 8: ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 9: ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where']\n",
      "Document 10: ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "OrderedDict({'angel': [3, OrderedDict({6: [0], 7: [0], 8: [0]})], 'antoni': [3, OrderedDict({0: [0], 1: [0], 5: [0]})], 'brutu': [3, OrderedDict({0: [1], 1: [1], 3: [0]})], 'caeser': [5, OrderedDict({0: [2], 1: [2], 3: [1], 4: [0], 5: [1]})], 'calpurnia': [1, OrderedDict({1: [3]})], 'cleopatra': [1, OrderedDict({0: [3]})], 'fear': [3, OrderedDict({6: [2], 7: [2], 9: [1]})], 'fool': [4, OrderedDict({6: [1], 7: [1], 8: [1], 9: [0]})], 'in': [4, OrderedDict({6: [3], 7: [3], 8: [2], 9: [2]})], 'merci': [5, OrderedDict({0: [4], 2: [0], 3: [2], 4: [1], 5: [2]})], 'rush': [4, OrderedDict({6: [4], 7: [4], 8: [3], 9: [3]})], 'to': [4, OrderedDict({6: [5], 7: [5], 8: [4], 9: [4]})], 'tread': [4, OrderedDict({6: [6], 7: [6], 8: [5], 9: [5]})], 'where': [4, OrderedDict({6: [7], 7: [7], 8: [6], 9: [6]})], 'worser': [4, OrderedDict({0: [5], 2: [1], 3: [3], 4: [2]})]})\n",
      "[[], [], [], [], [], [], [], [], [], []]\n",
      "[[], [], [], [], [], [1, 2], [1, 2], [1], [0, 1], []]\n",
      "6\n",
      "7\n",
      "9\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni        1     1     0     0     0     1     0     0     0      0\n",
      "brutu         1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "merci         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angel         0     0     0     0     0     0     1     1     1      0\n",
      "fool          0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutu       1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "merci       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angel       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fool        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "          freq       idf\n",
      "antoni     3.0  0.522879\n",
      "brutu      3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "merci      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angel      3.0  0.522879\n",
      "fool       4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antoni          0.0       0.0       0.0  \n",
      "brutu           0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "merci           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angel      0.522879  0.522879       0.0  \n",
      "fool        0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "   doc1_len  doc2_len  doc3_len  doc4_len  doc5_len  doc6_len  doc7_len  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747   0.67427  1.223496   \n",
      "\n",
      "   doc8_len  doc9_len  doc10_len  \n",
      "0  1.223496  1.106137   1.106137  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "      <th>doc7</th>\n",
       "      <th>doc8</th>\n",
       "      <th>doc9</th>\n",
       "      <th>doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.235250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0.728087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603298</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.508263</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.472707</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
       "antoni     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
       "brutu      0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
       "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
       "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "merci      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
       "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
       "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
       "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               doc7      doc8      doc9     doc10  \n",
       "antoni     0.000000  0.000000  0.000000  0.000000  \n",
       "brutu      0.000000  0.000000  0.000000  0.000000  \n",
       "caeser     0.000000  0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
       "merci      0.000000  0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  0.000000  \n",
       "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
       "angel      0.427365  0.427365  0.472707  0.000000  \n",
       "fool       0.325248  0.325248  0.359756  0.359756  \n",
       "fear       0.427365  0.427365  0.000000  0.472707  \n",
       "in         0.325248  0.325248  0.359756  0.359756  \n",
       "rush       0.325248  0.325248  0.359756  0.359756  \n",
       "to         0.325248  0.325248  0.359756  0.359756  \n",
       "tread      0.325248  0.325248  0.359756  0.359756  \n",
       "where      0.325248  0.325248  0.359756  0.359756  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from phase1 import *\n",
    "\n",
    "documents= stemmed_documents\n",
    "all_words=[]\n",
    "\n",
    "for doc in documents:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    "\n",
    "# print(dict.fromkeys(all_words,0))\n",
    "\n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word] +=1\n",
    "    return words_found\n",
    "\n",
    "term_freq= pd.DataFrame(get_term_freq(documents[0]).values(),index=get_term_freq(documents[0]).keys())\n",
    "\n",
    "\n",
    "for i in range(1,len(documents)):\n",
    "    term_freq[i]= get_term_freq(documents[i]).values()\n",
    "\n",
    "# print(term_freq)\n",
    "\n",
    "term_freq.columns=['doc'+ str(i) for i in range(1,11)]\n",
    "print(term_freq)\n",
    "\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "        return math.log(x)+1\n",
    "    return 0\n",
    "\n",
    "for i in range (1,len(documents)+1):\n",
    "    term_freq['doc'+str(i)]=term_freq['doc'+str(i)].apply(get_weighted_term_freq)\n",
    "\n",
    "print(term_freq)\n",
    "# idf is log(doc num/ term freq in doc)\n",
    "tfd=pd.DataFrame(columns=['freq','idf'])\n",
    "\n",
    "for i in range(len(term_freq)):\n",
    "\n",
    "    frequency=term_freq.iloc[i].values.sum()\n",
    "\n",
    "    tfd.loc[i ,'freq']= frequency\n",
    "\n",
    "    tfd.loc[i ,'idf']=math.log10(10 / float((frequency)) )\n",
    "\n",
    "tfd.index= term_freq.index\n",
    "print(tfd)    \n",
    "\n",
    "\n",
    "##### TF IDF #####\n",
    "\n",
    "term_freq_inverse_doc_freq= term_freq.multiply(tfd['idf'], axis=0)\n",
    "\n",
    "print(term_freq_inverse_doc_freq)\n",
    "\n",
    "\n",
    "####### doc length\n",
    "\n",
    "document_length=pd.DataFrame()\n",
    "\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inverse_doc_freq[col].apply(lambda x : x**2).sum())\n",
    "\n",
    "for column in term_freq_inverse_doc_freq.columns:\n",
    "    document_length.loc[0 , column+'_len']= get_docs_length(column)\n",
    "\n",
    "print(document_length)\n",
    "\n",
    "\n",
    "#### normalized TF IDF ######\n",
    "\n",
    "\n",
    "normalized_term_freq_idf= pd.DataFrame()\n",
    "\n",
    "def get_normalized(col , x):\n",
    "    try:\n",
    "        return x / document_length[col+'_len'].values[0]\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "for column in term_freq_inverse_doc_freq.columns:\n",
    "    normalized_term_freq_idf[column]= term_freq_inverse_doc_freq[column].apply(lambda x : get_normalized(column , x))\n",
    "\n",
    "normalized_term_freq_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3490342560.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[32], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    porter = PorterStemmer()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Assume normalized_term_freq_idf, tfd, and other required functions are defined\n",
    "\n",
    "# def query_boolean(q):\n",
    "    porter = PorterStemmer()\n",
    "    query_tokens = word_tokenize(q)\n",
    "    stemmed_query= [porter.stem(token) for token in query_tokens]\n",
    "\n",
    "    # Check for boolean operators\n",
    "    if ' AND ' in q:\n",
    "        operator = 'AND'\n",
    "        query_terms = [term.strip() for term in q.split('AND')]\n",
    "    elif ' OR ' in q:\n",
    "        operator = 'OR'\n",
    "        query_terms = [term.strip() for term in q.split('OR')]\n",
    "    else:\n",
    "        operator = 'AND'  # Default to OR if no explicit operator is provided\n",
    "        query_terms = [term.strip() for term in q.split()]\n",
    "\n",
    "    # Initialize an empty dataframe\n",
    "    query_result = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "\n",
    "    for term in query_terms:\n",
    "        # Stem each term\n",
    "        term_tokens = word_tokenize(term)\n",
    "        stemmed_term = [porter.stem(token) for token in term_tokens]\n",
    "\n",
    "        # Create a query vector for the current term\n",
    "        query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "        query['tf'] = [1 if x in stemmed_term else 0 for x in normalized_term_freq_idf.index]\n",
    "        query['w_tf'] = query['tf'].apply(lambda x: get_weighted_term_freq(x))\n",
    "        product = normalized_term_freq_idf.multiply(query['w_tf'], axis= 0)\n",
    "        query['idf'] = tfd['idf'] * query['w_tf']\n",
    "        query['tf_idf'] = query['idf'] * query['w_tf']\n",
    "        query['norm'] = normalize(query[['idf']], norm='l2', axis=0)\n",
    "\n",
    "        # for i in range(len(query)):\n",
    "        #     query['norm'].iloc[i]= query['idf'].iloc[i] / math.sqrt(sum(query['idf'].values**2))\n",
    "        product2=product.multiply(query['norm'], axis=0)\n",
    "\n",
    "        # Perform AND or OR operation\n",
    "        if operator == 'AND':\n",
    "            query_result = pd.concat([query_result, query], axis=1, join='inner')  # Use inner join for AND\n",
    "        elif operator == 'OR':\n",
    "            query_result = pd.concat([query_result, query], axis=1, join='outer')\n",
    "\n",
    "    # Return the final result after AND or OR operation\n",
    "    # query_len(query_result)\n",
    "    # return query_result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling boolean operators\n",
    "boolean_operators = ['and', 'or', 'not']\n",
    "boolean_operator = None\n",
    "\n",
    "for op in boolean_operators:\n",
    "    if op in query_terms:\n",
    "        boolean_operator = op\n",
    "        break\n",
    "\n",
    "matched_documents = None\n",
    "\n",
    "# Split the query based on the boolean operator\n",
    "query_parts = user_query.lower().split(boolean_operator)\n",
    "# Tokenization and stemming for each part\n",
    "query_parts_terms = [\n",
    "    [porter_stemmer.stem(word) for word in word_tokenize(part)] for part in query_parts\n",
    "]\n",
    "print(query_parts_terms)\n",
    "\n",
    "if boolean_operator:\n",
    "    # Find matched documents for each part\n",
    "    matched_documents_parts = []\n",
    "    for part_terms in query_parts_terms:\n",
    "        matched_documents_part = set(range(1, len(document_lengths) + 1))  # Initialize with all documents\n",
    "        for term in part_terms:\n",
    "            if term in positional_index:\n",
    "                matched_documents_part &= set(positional_index[term]['docs'].keys()) # type: ignore\n",
    "        matched_documents_parts.append(matched_documents_part)\n",
    "    print(matched_documents_parts)\n",
    "    # Apply boolean operator\n",
    "    if boolean_operator == 'and':\n",
    "        matched_documents = set.intersection(*matched_documents_parts)\n",
    "    elif boolean_operator == 'or':\n",
    "        matched_documents = set.union(*matched_documents_parts)\n",
    "    elif boolean_operator == 'not':\n",
    "        matched_documents = set.difference(set(range(1, len(document_lengths) + 1)), *matched_documents_parts)\n",
    "    \n",
    "else:\n",
    "    # No boolean operator, find matched documents without considering boolean logic\n",
    "    matched_documents = set(range(1, len(document_lengths) + 1))\n",
    "    for term in query_terms:\n",
    "        if term in positional_index:\n",
    "            matched_documents &= set(positional_index[term]['docs'].keys()) # type: ignore\n",
    "\n",
    "print(\"Matched Documents:\", matched_documents)\n",
    "\n",
    "\n",
    "# Get distinct terms in the query\n",
    "query_terms = [item for sublist in query_parts_terms for item in sublist]\n",
    "original_query_terms = query_terms\n",
    "query_terms = list(set(query_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>w_tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>norm</th>\n",
       "      <th>tf</th>\n",
       "      <th>w_tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>norm</th>\n",
       "      <th>tf</th>\n",
       "      <th>w_tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tf  w_tf       idf    tf_idf  norm  tf  w_tf  idf tf_idf  norm  tf  \\\n",
       "antoni      1   1.0  0.522879  0.522879   1.0   0     0  0.0    0.0   0.0   0   \n",
       "brutu       0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   1   \n",
       "caeser      0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "cleopatra   0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "merci       0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "worser      0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "calpurnia   0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "angel       0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "fool        0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "fear        0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "in          0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "rush        0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "to          0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "tread       0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "where       0   0.0       0.0       0.0   0.0   0     0  0.0    0.0   0.0   0   \n",
       "\n",
       "           w_tf       idf    tf_idf  norm  \n",
       "antoni      0.0       0.0       0.0   0.0  \n",
       "brutu       1.0  0.522879  0.522879   1.0  \n",
       "caeser      0.0       0.0       0.0   0.0  \n",
       "cleopatra   0.0       0.0       0.0   0.0  \n",
       "merci       0.0       0.0       0.0   0.0  \n",
       "worser      0.0       0.0       0.0   0.0  \n",
       "calpurnia   0.0       0.0       0.0   0.0  \n",
       "angel       0.0       0.0       0.0   0.0  \n",
       "fool        0.0       0.0       0.0   0.0  \n",
       "fear        0.0       0.0       0.0   0.0  \n",
       "in          0.0       0.0       0.0   0.0  \n",
       "rush        0.0       0.0       0.0   0.0  \n",
       "to          0.0       0.0       0.0   0.0  \n",
       "tread       0.0       0.0       0.0   0.0  \n",
       "where       0.0       0.0       0.0   0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= 'antony OR brutus'\n",
    "# def phrse_query(q):\n",
    "porter = PorterStemmer()\n",
    "query_tokens = word_tokenize(q)\n",
    "stemmed_query = [porter.stem(token) for token in query_tokens]\n",
    "q= ' '.join(stemmed_query)\n",
    "query_boolean(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_len(query):\n",
    "    query_length = 0\n",
    "\n",
    "    # Iterate through the query terms\n",
    "    for term in q.split():\n",
    "        term_tokens = word_tokenize(term)\n",
    "        stemmed_term = [porter.stem(token) for token in term_tokens]\n",
    "\n",
    "        # Check if the term is present in the query vector\n",
    "        if stemmed_term[0] in query.index:\n",
    "            query_length += query['idf'].loc[stemmed_term[0]] ** 2\n",
    "\n",
    "    # Take the square root of the sum of squared IDF values\n",
    "    query_length = math.sqrt(query_length)\n",
    "query_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'product2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Iterate through the columns of the product2 dataframe\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct2\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract the relevant IDF values from the query vector\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     query_idf_values \u001b[38;5;241m=\u001b[39m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[product2\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Check if any of the relevant IDF values is zero\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'product2' is not defined"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "# Iterate through the columns of the product2 dataframe\n",
    "for col in product2.columns:\n",
    "    # Extract the relevant IDF values from the query vector\n",
    "    query_idf_values = query['idf'].loc[product2.index]\n",
    "\n",
    "    # Check if any of the relevant IDF values is zero\n",
    "    if 0 in query_idf_values.values:\n",
    "        # Skip if any term in the query has IDF of 0\n",
    "        pass\n",
    "    else:\n",
    "        # Calculate the score by summing the product of normalized TF-IDF values and query IDF values\n",
    "        scores[col] = (product2[col] * query_idf_values).sum()\n",
    "\n",
    "# Print or use the scores as needed\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = {}\n",
    "\n",
    "# Iterate through the columns of the product2 dataframe\n",
    "for col in product2.columns:\n",
    "    # Extract the relevant IDF values from the query vector\n",
    "    query_idf_values = query['idf'].loc[product2.index]\n",
    "\n",
    "    # Calculate the score by summing the product of normalized TF-IDF values and query IDF values\n",
    "    scores[col] = (product2[col] * query_idf_values).sum()\n",
    "\n",
    "# Filter out documents that don't contain any term from the query\n",
    "filtered_scores = {key: score for key, score in scores.items() if any(query['tf'].loc[product2.index].astype(bool))}\n",
    "filtered_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_res = product2[filtered_scores.keys()].loc[query.index.intersection(q.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_sum=prod_res.sum()\n",
    "prod_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score=sorted(prod_sum.items(), key= lambda x :x[1], reverse= True)\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in final_score:\n",
    "    print(doc[0], end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
